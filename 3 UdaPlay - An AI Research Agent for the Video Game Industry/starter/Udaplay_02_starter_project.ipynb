{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "part2-header",
   "metadata": {},
   "source": [
    "# [STARTER] Udaplay Project - Part 2\n",
    "\n",
    "## Part 02 - AI Agent Development\n",
    "\n",
    "In this part, you'll build an intelligent AI agent that combines local knowledge (RAG) with web search capabilities to answer questions about video games.\n",
    "\n",
    "The agent will have the following capabilities:\n",
    "1. Answer questions using internal knowledge (RAG)\n",
    "2. Search the web when needed\n",
    "3. Maintain conversation state\n",
    "4. Return structured outputs\n",
    "5. Store useful information for future use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-header",
   "metadata": {},
   "source": [
    "### Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "setup-imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from typing import List, Dict, Any\n",
    "from dotenv import load_dotenv\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "import openai\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Configure API keys\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Initialize ChromaDB\n",
    "chroma_client = chromadb.PersistentClient(path=\"chromadb\")\n",
    "collection = chroma_client.get_collection(\"udaplay\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tools-header",
   "metadata": {},
   "source": [
    "### Required Tools Implementation\n",
    "\n",
    "You need to implement the following tools:\n",
    "1. `retrieve_game`: Search the vector database for game information\n",
    "2. `evaluate_retrieval`: Assess the quality of retrieved results\n",
    "3. `game_web_search`: Perform web searches for additional information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "retrieve-game-tool",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing retrieve_game tool:\n",
      "Found 5 racing games\n",
      "{\n",
      "  \"Platform\": \"PlayStation 1\",\n",
      "  \"Name\": \"Gran Turismo\",\n",
      "  \"YearOfRelease\": 1997,\n",
      "  \"Description\": \"A realistic racing simulator featuring a wide array of cars and tracks, setting a new standard for the genre.\",\n",
      "  \"Genre\": \"Racing\",\n",
      "  \"Publisher\": \"Sony Computer Entertainment\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "def retrieve_game(query: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Semantic search: Finds most relevant results in the vector DB\n",
    "    \n",
    "    Args:\n",
    "        query: a question about game industry\n",
    "    \n",
    "    Returns:\n",
    "        List of dictionaries, each containing:\n",
    "        - Platform: like Game Boy, Playstation 5, Xbox 360...\n",
    "        - Name: Name of the Game\n",
    "        - YearOfRelease: Year when that game was released for that platform\n",
    "        - Description: Additional details about the game\n",
    "        - Genre: Game genre\n",
    "        - Publisher: Game publisher\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Perform semantic search in the collection\n",
    "        results = collection.query(\n",
    "            query_texts=[query],\n",
    "            n_results=5,  # Return top 5 most relevant results\n",
    "            include=['metadatas', 'documents', 'distances']\n",
    "        )\n",
    "        \n",
    "        # Extract and format the results\n",
    "        games = []\n",
    "        if results['metadatas'] and results['metadatas'][0]:\n",
    "            for metadata in results['metadatas'][0]:\n",
    "                games.append({\n",
    "                    'Platform': metadata.get('Platform', 'Unknown'),\n",
    "                    'Name': metadata.get('Name', 'Unknown'),\n",
    "                    'YearOfRelease': metadata.get('YearOfRelease', 'Unknown'),\n",
    "                    'Description': metadata.get('Description', 'No description available'),\n",
    "                    'Genre': metadata.get('Genre', 'Unknown'),\n",
    "                    'Publisher': metadata.get('Publisher', 'Unknown')\n",
    "                })\n",
    "        \n",
    "        return games\n",
    "    except Exception as e:\n",
    "        print(f\"Error in retrieve_game: {e}\")\n",
    "        return []\n",
    "\n",
    "# Test the retrieve_game tool\n",
    "print(\"Testing retrieve_game tool:\")\n",
    "test_results = retrieve_game(\"racing games\")\n",
    "print(f\"Found {len(test_results)} racing games\")\n",
    "if test_results:\n",
    "    print(json.dumps(test_results[0], indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "evaluate-retrieval-tool",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing evaluate_retrieval tool:\n",
      "{\n",
      "  \"relevance_score\": 0.5,\n",
      "  \"coverage_score\": 1.0,\n",
      "  \"confidence\": 0.75,\n",
      "  \"suggestions\": \"Results look good!\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "def evaluate_retrieval(query: str, results: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Evaluate the quality of retrieved results\n",
    "    \n",
    "    Args:\n",
    "        query: The original query\n",
    "        results: List of retrieved game results\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary containing evaluation metrics:\n",
    "        - relevance_score: 0-1 score of how relevant results are\n",
    "        - coverage_score: 0-1 score of how well results cover the query\n",
    "        - confidence: Overall confidence in the results\n",
    "        - suggestions: Suggestions for improving the search\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not results:\n",
    "            return {\n",
    "                'relevance_score': 0.0,\n",
    "                'coverage_score': 0.0,\n",
    "                'confidence': 0.0,\n",
    "                'suggestions': 'No results found. Consider broadening your search terms.'\n",
    "            }\n",
    "        \n",
    "        # Simple relevance scoring based on query terms in results\n",
    "        query_terms = query.lower().split()\n",
    "        total_relevance = 0\n",
    "        \n",
    "        for result in results:\n",
    "            result_text = f\"{result.get('Name', '')} {result.get('Description', '')} {result.get('Genre', '')}\".lower()\n",
    "            matches = sum(1 for term in query_terms if term in result_text)\n",
    "            total_relevance += matches / len(query_terms) if query_terms else 0\n",
    "        \n",
    "        relevance_score = min(1.0, total_relevance / len(results))\n",
    "        coverage_score = min(1.0, len(results) / 5.0)  # Assuming we want 5 results\n",
    "        confidence = (relevance_score + coverage_score) / 2\n",
    "        \n",
    "        suggestions = []\n",
    "        if relevance_score < 0.5:\n",
    "            suggestions.append('Try using more specific game names or genres')\n",
    "        if coverage_score < 0.8:\n",
    "            suggestions.append('Consider broadening your search terms')\n",
    "        \n",
    "        return {\n",
    "            'relevance_score': round(relevance_score, 3),\n",
    "            'coverage_score': round(coverage_score, 3),\n",
    "            'confidence': round(confidence, 3),\n",
    "            'suggestions': '; '.join(suggestions) if suggestions else 'Results look good!'\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in evaluate_retrieval: {e}\")\n",
    "        return {\n",
    "            'relevance_score': 0.0,\n",
    "            'coverage_score': 0.0,\n",
    "            'confidence': 0.0,\n",
    "            'suggestions': f'Error occurred: {str(e)}'\n",
    "        }\n",
    "\n",
    "# Test the evaluate_retrieval tool\n",
    "print(\"Testing evaluate_retrieval tool:\")\n",
    "evaluation = evaluate_retrieval(\"racing games\", test_results)\n",
    "print(json.dumps(evaluation, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "game-web-search-tool",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing game_web_search tool:\n",
      "{\n",
      "  \"search_results\": [\n",
      "    {\n",
      "      \"title\": \"What Are the Biggest Gaming Trends of 2024? | Fast Feed\",\n",
      "      \"content\": \"The biggest social trends in gaming in 2024  In 2024, leading social trends in gaming are esports, online multiplayer and streaming. Professional esports is huge now.\",\n",
      "      \"url\": \"https://blog.frontier.com/2024/04/what-are-the-biggest-gaming-trends-of-2024/\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Top 15 Mobile Game Development Trends to Watch Out in 2024-26\",\n",
      "      \"content\": \"Key trends include AR/VR, cloud gaming, blockchain technology, hyper-casual games, and the rise of indie games, among others.\",\n",
      "      \"url\": \"https://syndelltech.com/top-mobile-game-development-trends/\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Gaming industry trends to watch in 2025: Distribution ... - GeekWire\",\n",
      "      \"content\": \"As 2024 draws to a close, one advisory firm predicts the video game industry will see a major rebound in 2025 following two years of declines.\",\n",
      "      \"url\": \"https://www.geekwire.com/2024/gaming-industry-trends-to-watch-in-2025-distribution-channels-console-wars-and-more/\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"The global games market will generate $187.7 billion in 2024\",\n",
      "      \"content\": \"The global games market will generate $187.7 billion in 2024, representing +2.1% year-on-year growth. PC and console game revenues will account for 51% of\",\n",
      "      \"url\": \"https://newzoo.com/resources/blog/global-games-market-revenue-estimates-and-forecasts-in-2024\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"The Future of Gaming: Game Development Trends from Our 2024 ...\",\n",
      "      \"content\": \"We surveyed game developers around the globe for insights on the future of gaming and game development trends in the industry.\",\n",
      "      \"url\": \"https://www.perforce.com/blog/vcs/future-of-game-development-trends\"\n",
      "    }\n",
      "  ],\n",
      "  \"summary\": \"Found 5 relevant results for 'latest gaming industry trends 2024'. The search covers various aspects of the gaming industry including reviews, news, and historical information.\",\n",
      "  \"sources\": [\n",
      "    \"https://blog.frontier.com/2024/04/what-are-the-biggest-gaming-trends-of-2024/\",\n",
      "    \"https://syndelltech.com/top-mobile-game-development-trends/\",\n",
      "    \"https://www.geekwire.com/2024/gaming-industry-trends-to-watch-in-2025-distribution-channels-console-wars-and-more/\",\n",
      "    \"https://newzoo.com/resources/blog/global-games-market-revenue-estimates-and-forecasts-in-2024\",\n",
      "    \"https://www.perforce.com/blog/vcs/future-of-game-development-trends\"\n",
      "  ],\n",
      "  \"error\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "def game_web_search(query: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Perform web search for additional game information\n",
    "    \n",
    "    Args:\n",
    "        query: Search query about games\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary containing:\n",
    "        - search_results: List of search results\n",
    "        - summary: Summary of findings\n",
    "        - sources: List of source URLs\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Check if Tavily client is available\n",
    "        if not hasattr(game_web_search, 'tavily_client'):\n",
    "            try:\n",
    "                tavily_api_key = os.getenv('TAVILY_API_KEY')\n",
    "                if tavily_api_key:\n",
    "                    from tavily import TavilyClient\n",
    "                    game_web_search.tavily_client = TavilyClient(api_key=tavily_api_key)\n",
    "                else:\n",
    "                    game_web_search.tavily_client = None\n",
    "            except ImportError:\n",
    "                game_web_search.tavily_client = None\n",
    "            except Exception:\n",
    "                game_web_search.tavily_client = None\n",
    "        \n",
    "        # If client is not available, return informative message\n",
    "        if not game_web_search.tavily_client:\n",
    "            return {\n",
    "                'search_results': [],\n",
    "                'summary': 'Tavily API key not found or client not initialized. Web search unavailable.',\n",
    "                'sources': [],\n",
    "                'error': 'CLIENT_NOT_AVAILABLE'\n",
    "            }\n",
    "        \n",
    "        # Perform web search using Tavily\n",
    "        search_response = game_web_search.tavily_client.search(\n",
    "            query=query,\n",
    "            search_depth=\"basic\",\n",
    "            max_results=5\n",
    "        )\n",
    "        \n",
    "        # Extract relevant information\n",
    "        results = search_response.get('results', [])\n",
    "        \n",
    "        search_results = []\n",
    "        sources = []\n",
    "        \n",
    "        for result in results:\n",
    "            search_results.append({\n",
    "                'title': result.get('title', 'No title'),\n",
    "                'content': result.get('content', 'No content'),\n",
    "                'url': result.get('url', 'No URL')\n",
    "            })\n",
    "            sources.append(result.get('url', 'No URL'))\n",
    "        \n",
    "        # Create a summary\n",
    "        summary = f\"Found {len(search_results)} relevant results for '{query}'. \"\n",
    "        if search_results:\n",
    "            summary += \"The search covers various aspects of the gaming industry including reviews, news, and historical information.\"\n",
    "        \n",
    "        return {\n",
    "            'search_results': search_results,\n",
    "            'summary': summary,\n",
    "            'sources': sources,\n",
    "            'error': None\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in game_web_search: {e}\")\n",
    "        return {\n",
    "            'search_results': [],\n",
    "            'summary': f'Error occurred during web search: {str(e)}',\n",
    "            'sources': [],\n",
    "            'error': 'SEARCH_ERROR'\n",
    "        }\n",
    "\n",
    "# Test the game_web_search tool\n",
    "print(\"Testing game_web_search tool:\")\n",
    "web_results = game_web_search(\"latest gaming industry trends 2024\")\n",
    "print(json.dumps(web_results, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agent-header",
   "metadata": {},
   "source": [
    "### AI Agent Implementation\n",
    "\n",
    "Now let's create the main AI agent that combines all these tools to answer questions intelligently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "agent-class",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UdaplayAgent initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "class UdaplayAgent:\n",
    "    \"\"\"\n",
    "    AI Agent for answering questions about video games using RAG and web search\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.conversation_history = []\n",
    "        self.tools = {\n",
    "            'retrieve_game': retrieve_game,\n",
    "            'evaluate_retrieval': evaluate_retrieval,\n",
    "            'game_web_search': game_web_search\n",
    "        }\n",
    "    \n",
    "    def add_to_history(self, role: str, content: str):\n",
    "        \"\"\"Add message to conversation history\"\"\"\n",
    "        self.conversation_history.append({\n",
    "            'role': role,\n",
    "            'content': content,\n",
    "            'timestamp': len(self.conversation_history)\n",
    "        })\n",
    "    \n",
    "    def get_response(self, query: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Main method to get a response from the agent\n",
    "        \n",
    "        Args:\n",
    "            query: User's question about games\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary containing the agent's response and metadata\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Add user query to history\n",
    "            self.add_to_history('user', query)\n",
    "            \n",
    "            # Step 1: Try to find information in local knowledge base\n",
    "            local_results = self.tools['retrieve_game'](query)\n",
    "            \n",
    "            # Step 2: Evaluate the quality of local results\n",
    "            evaluation = self.tools['evaluate_retrieval'](query, local_results)\n",
    "            \n",
    "            # Step 3: Decide if web search is needed\n",
    "            web_results = None\n",
    "            if evaluation['confidence'] < 0.6 or len(local_results) < 2:\n",
    "                web_results = self.tools['game_web_search'](query)\n",
    "            \n",
    "            # Step 4: Generate comprehensive response\n",
    "            response = self._generate_response(query, local_results, evaluation, web_results)\n",
    "            \n",
    "            # Add agent response to history\n",
    "            self.add_to_history('assistant', response['answer'])\n",
    "            \n",
    "            return response\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_response = {\n",
    "                'answer': f'Sorry, I encountered an error: {str(e)}',\n",
    "                'local_results': [],\n",
    "                'web_results': None,\n",
    "                'evaluation': {'confidence': 0.0, 'error': str(e)},\n",
    "                'sources': []\n",
    "            }\n",
    "            self.add_to_history('assistant', error_response['answer'])\n",
    "            return error_response\n",
    "    \n",
    "    def _generate_response(self, query: str, local_results: List[Dict], \n",
    "                          evaluation: Dict, web_results: Dict = None) -> Dict[str, Any]:\n",
    "        \"\"\"Generate a comprehensive response based on available information\"\"\"\n",
    "        \n",
    "        # Build the response\n",
    "        answer_parts = []\n",
    "        sources = []\n",
    "        \n",
    "        # Add local knowledge results\n",
    "        if local_results:\n",
    "            answer_parts.append(\"Based on my knowledge base:\")\n",
    "            for i, result in enumerate(local_results[:3], 1):\n",
    "                answer_parts.append(f\"{i}. {result['Name']} ({result['Platform']}, {result['YearOfRelease']}) - {result['Description']}\")\n",
    "            \n",
    "            # Add evaluation insights\n",
    "            if evaluation['confidence'] < 0.7:\n",
    "                answer_parts.append(f\"\\nNote: My confidence in these results is {evaluation['confidence']}. {evaluation['suggestions']}\")\n",
    "        \n",
    "        # Add web search results if available\n",
    "        if web_results and web_results.get('search_results') and not web_results.get('error'):\n",
    "            answer_parts.append(\"\\nAdditional information from recent sources:\")\n",
    "            for result in web_results['search_results'][:2]:\n",
    "                answer_parts.append(f\"â€¢ {result['title']}: {result['content'][:150]}...\")\n",
    "                sources.append(result['url'])\n",
    "            \n",
    "            answer_parts.append(f\"\\n{web_results['summary']}\")\n",
    "        elif web_results and web_results.get('error'):\n",
    "            answer_parts.append(f\"\\nNote: {web_results['summary']}\")\n",
    "        \n",
    "        # If no results found\n",
    "        if not local_results and not web_results:\n",
    "            answer_parts.append(\"I couldn't find specific information about that in my knowledge base or recent sources. \")\n",
    "            answer_parts.append(\"Try rephrasing your question or asking about a different aspect of gaming.\")\n",
    "        \n",
    "        # Combine all parts\n",
    "        full_answer = \"\\n\\n\".join(answer_parts)\n",
    "        \n",
    "        return {\n",
    "            'answer': full_answer,\n",
    "            'local_results': local_results,\n",
    "            'web_results': web_results,\n",
    "            'evaluation': evaluation,\n",
    "            'sources': sources\n",
    "        }\n",
    "    \n",
    "    def get_conversation_summary(self) -> str:\n",
    "        \"\"\"Get a summary of the conversation history\"\"\"\n",
    "        if not self.conversation_history:\n",
    "            return \"No conversation history yet.\"\n",
    "        \n",
    "        summary = f\"Conversation Summary ({len(self.conversation_history)} messages):\\n\"\n",
    "        for msg in self.conversation_history[-5:]:  # Last 5 messages\n",
    "            summary += f\"{msg['role'].title()}: {msg['content'][:100]}...\\n\"\n",
    "        \n",
    "        return summary\n",
    "\n",
    "# Initialize the agent\n",
    "agent = UdaplayAgent()\n",
    "print(\"UdaplayAgent initialized successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "testing-header",
   "metadata": {},
   "source": [
    "### Testing the Agent\n",
    "\n",
    "Let's test our agent with various types of questions to see how it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "test-queries",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing the UdaplayAgent with various queries:\n",
      "\n",
      "\n",
      "--- Test Query 1: What racing games are available? ---\n",
      "Answer: Based on my knowledge base:\n",
      "\n",
      "1. Gran Turismo 5 (PlayStation 3, 2010) - A comprehensive racing simulator featuring a vast selection of vehicles and tracks, with realistic driving physics.\n",
      "\n",
      "2. Gran Turismo (PlayStation 1, 1997) - A realistic racing simulator featuring a wide array of cars and tracks, ...\n",
      "Confidence: 0.6\n",
      "Local Results: 5\n",
      "Web Results: No\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Test Query 2: Tell me about platformer games ---\n",
      "Answer: Based on my knowledge base:\n",
      "\n",
      "1. Super Mario 64 (Nintendo 64, 1996) - A groundbreaking 3D platformer that set new standards for the genre, featuring Mario's quest to rescue Princess Peach.\n",
      "\n",
      "2. Super Mario World (Super Nintendo Entertainment System (SNES), 1990) - A classic platformer where Mario emba...\n",
      "Confidence: 0.66\n",
      "Local Results: 5\n",
      "Web Results: No\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Test Query 3: What games were released in the 1990s? ---\n",
      "Answer: Based on my knowledge base:\n",
      "\n",
      "1. Super Mario World (Super Nintendo Entertainment System (SNES), 1990) - A classic platformer where Mario embarks on a quest to save Princess Toadstool and Dinosaur Land from Bowser.\n",
      "\n",
      "2. PokÃ©mon Gold and Silver (Game Boy Color, 1999) - Second-generation PokÃ©mon games in...\n",
      "Confidence: 0.643\n",
      "Local Results: 5\n",
      "Web Results: No\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Test Query 4: Which games are available for PlayStation? ---\n",
      "Answer: Based on my knowledge base:\n",
      "\n",
      "1. Gran Turismo 5 (PlayStation 3, 2010) - A comprehensive racing simulator featuring a vast selection of vehicles and tracks, with realistic driving physics.\n",
      "\n",
      "2. Gran Turismo (PlayStation 1, 1997) - A realistic racing simulator featuring a wide array of cars and tracks, ...\n",
      "Confidence: 0.517\n",
      "Local Results: 5\n",
      "Web Results: Yes\n",
      "Sources: 2 URLs\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test queries to evaluate the agent's performance\n",
    "test_queries = [\n",
    "    \"What racing games are available?\",\n",
    "    \"Tell me about platformer games\",\n",
    "    \"What games were released in the 1990s?\",\n",
    "    \"Which games are available for PlayStation?\"\n",
    "]\n",
    "\n",
    "print(\"Testing the UdaplayAgent with various queries:\\n\")\n",
    "\n",
    "for i, query in enumerate(test_queries, 1):\n",
    "    print(f\"\\n--- Test Query {i}: {query} ---\")\n",
    "    response = agent.get_response(query)\n",
    "    \n",
    "    print(f\"Answer: {response['answer'][:300]}...\")\n",
    "    print(f\"Confidence: {response['evaluation']['confidence']}\")\n",
    "    print(f\"Local Results: {len(response['local_results'])}\")\n",
    "    print(f\"Web Results: {'Yes' if response['web_results'] and not response['web_results'].get('error') else 'No'}\")\n",
    "    \n",
    "    if response['sources']:\n",
    "        print(f\"Sources: {len(response['sources'])} URLs\")\n",
    "    \n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conversation-header",
   "metadata": {},
   "source": [
    "### Interactive Conversation\n",
    "\n",
    "Now you can have an interactive conversation with the agent. Ask it questions about games!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "interactive-chat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with a specific question:\n",
      "\n",
      "Question: What are some popular racing games from the 1990s?\n",
      "\n",
      "Answer: Based on my knowledge base:\n",
      "\n",
      "1. Gran Turismo (PlayStation 1, 1997) - A realistic racing simulator featuring a wide array of cars and tracks, setting a new standard for the genre.\n",
      "\n",
      "2. Gran Turismo 5 (PlayStation 3, 2010) - A comprehensive racing simulator featuring a vast selection of vehicles and tracks, with realistic driving physics.\n",
      "\n",
      "3. Super Mario World (Super Nintendo Entertainment System (SNES), 1990) - A classic platformer where Mario embarks on a quest to save Princess Toadstool and Dinosaur Land from Bowser.\n",
      "\n",
      "\n",
      "Note: My confidence in these results is 0.567. Try using more specific game names or genres\n",
      "\n",
      "\n",
      "Additional information from recent sources:\n",
      "\n",
      "â€¢ What are the Best Racing Games From the 90s?: What are the Best Racing Games From the 90s? Â· 1 Mario Kart 64 (1996) Â· 2 Gran Turismo (1997) Â· 3 Ridge Racer Type 4 (1999) Â· 4 Sega Rally...\n",
      "\n",
      "â€¢ The 11 best racing games of the 1990s (List) | GRR: We go through the best racing games of the 1990s, from arcade legends like *Sega Rally* and *Ridge Racer* and long-lost franchises like *Lotus Turbo C...\n",
      "\n",
      "\n",
      "Found 5 relevant results for 'What are some popular racing games from the 1990s?'. The search covers various aspects of the gaming industry including reviews, news, and historical information.\n"
     ]
    }
   ],
   "source": [
    "def chat_with_agent():\n",
    "    \"\"\"Interactive chat function with the agent\"\"\"\n",
    "    print(\"Welcome to Udaplay! Ask me anything about video games.\")\n",
    "    print(\"Type 'quit' to exit, 'history' to see conversation history, or 'summary' for a summary.\\n\")\n",
    "    \n",
    "    while True:\n",
    "        user_input = input(\"\\nYou: \").strip()\n",
    "        \n",
    "        if user_input.lower() == 'quit':\n",
    "            print(\"\\nThanks for chatting! Goodbye!\")\n",
    "            break\n",
    "        elif user_input.lower() == 'history':\n",
    "            print(\"\\nConversation History:\")\n",
    "            for msg in agent.conversation_history:\n",
    "                print(f\"{msg['role'].title()}: {msg['content'][:100]}...\")\n",
    "            continue\n",
    "        elif user_input.lower() == 'summary':\n",
    "            print(\"\\n\" + agent.get_conversation_summary())\n",
    "            continue\n",
    "        elif not user_input:\n",
    "            continue\n",
    "        \n",
    "        # Get response from agent\n",
    "        response = agent.get_response(user_input)\n",
    "        \n",
    "        print(f\"\\nAgent: {response['answer']}\")\n",
    "        \n",
    "        # Show confidence and sources if available\n",
    "        if response['evaluation']['confidence'] < 0.7:\n",
    "            print(f\"\\n[Confidence: {response['evaluation']['confidence']}]\")\n",
    "        if response['sources']:\n",
    "            print(f\"\\nSources: {', '.join(response['sources'][:2])}\")\n",
    "\n",
    "# Uncomment the line below to start interactive chat\n",
    "# chat_with_agent()\n",
    "\n",
    "# For now, let's test with a specific question\n",
    "print(\"Testing with a specific question:\")\n",
    "question = \"What are some popular racing games from the 1990s?\"\n",
    "response = agent.get_response(question)\n",
    "print(f\"\\nQuestion: {question}\")\n",
    "print(f\"\\nAnswer: {response['answer']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enhancement-header",
   "metadata": {},
   "source": [
    "### Advanced Features and Enhancements\n",
    "\n",
    "Here are some ideas for enhancing your agent:\n",
    "\n",
    "1. **Long-term Memory**: Store conversation history in a database\n",
    "2. **Better Evaluation**: Use LLM-based evaluation for more accurate assessment\n",
    "3. **Tool Chaining**: Automatically chain tools based on query complexity\n",
    "4. **Response Templates**: Create structured response templates for different query types\n",
    "5. **Error Handling**: Implement more sophisticated error handling and recovery\n",
    "6. **Performance Metrics**: Track and analyze agent performance over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "enhancement-example",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enhanced evaluation function created (example implementation)\n"
     ]
    }
   ],
   "source": [
    "# Example of how you could enhance the agent with better evaluation\n",
    "def enhanced_evaluation(query: str, results: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Enhanced evaluation using LLM for better assessment\n",
    "    This is an example of how you could improve the evaluation\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not results:\n",
    "            return {\n",
    "                'relevance_score': 0.0,\n",
    "                'coverage_score': 0.0,\n",
    "                'confidence': 0.0,\n",
    "                'suggestions': 'No results found. Consider broadening your search terms.'\n",
    "            }\n",
    "        \n",
    "        # Create a prompt for the LLM to evaluate results\n",
    "        evaluation_prompt = f\"\"\"\n",
    "        Evaluate the relevance of these game results to the query: \"{query}\"\n",
    "        \n",
    "        Results:\n",
    "        {json.dumps(results, indent=2)}\n",
    "        \n",
    "        Rate each result from 0-10 for relevance and provide an overall confidence score.\n",
    "        \"\"\"\n",
    "        \n",
    "        # This would use OpenAI's API for evaluation\n",
    "        # For now, return the basic evaluation\n",
    "        return evaluate_retrieval(query, results)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in enhanced_evaluation: {e}\")\n",
    "        return evaluate_retrieval(query, results)\n",
    "\n",
    "print(\"Enhanced evaluation function created (example implementation)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion-header",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Congratulations! You've successfully implemented:\n",
    "\n",
    "âœ… **Part 1**: Offline RAG with ChromaDB\n",
    "âœ… **Part 2**: AI Agent with multiple tools\n",
    "âœ… **Required Tools**: retrieve_game, evaluate_retrieval, game_web_search\n",
    "âœ… **Agent Capabilities**: Local knowledge + Web search + Conversation state\n",
    "\n",
    "Your Udaplay agent can now:\n",
    "- Answer questions using local game knowledge\n",
    "- Search the web for additional information\n",
    "- Maintain conversation context\n",
    "- Provide structured responses with confidence scores\n",
    "- Suggest improvements when results are insufficient\n",
    "\n",
    "### Next Steps:\n",
    "1. Test with various game-related queries\n",
    "2. Enhance the evaluation system\n",
    "3. Add more sophisticated memory management\n",
    "4. Implement additional tools as needed\n",
    "5. Deploy and monitor performance\n",
    "\n",
    "Happy gaming research! ðŸŽ®"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
